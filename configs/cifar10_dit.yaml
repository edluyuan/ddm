# Configuration for training the CIFAR-10 DiT-backed DDDM.
data_dir: ./data
out: ./outputs/cifar10_dit
epochs: 10
batch: 128
lr: 0.0001
weight_decay: 0.01
beta: 0.1
lam: 1.0
m: 8
w_bias: 0.0
grad_clip: 1.0
ckpt_every: 1
device: cuda
seed: 0
image_size: 32
patch_size: 4
embed_dim: 384
depth: 8
heads: 6
time_embed: 256
mlp_ratio: 4.0
workers: 4
sample_batch: 64
sample_steps: 20
eps_churn: 1.0
no_augment: false
eval_every: 1
eval_batch: 256
eval_samples: 1024
fid_samples: 10000
mmd_samples: 2048
mmd_sigma: 1.0
wandb: false
wandb_project: dddm-cifar10
wandb_name: cifar10-dit-baseline
